{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-25T20:04:31.021975Z",
     "start_time": "2025-06-25T20:04:27.107461Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch, os, random, copy\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "# from graph_aug import mask_nodes, mask_edges\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from ogb.utils import smiles2graph\n",
    "from dualgraph.mol import smiles2graphwithface, smiles2graphwithface_with_mask\n",
    "from dualgraph.gnn import GNN2\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from dualgraph.dataset import DGData\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from ogb.utils.features import (\n",
    "    allowable_features,\n",
    "    atom_to_feature_vector\n",
    ")\n",
    "\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "# from dualgraph.graph import getface"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:09:47.577068Z",
     "start_time": "2025-06-25T20:09:47.564067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "seed_everything(2024)\n",
    "\n",
    "device = 'cuda'"
   ],
   "id": "dd5ca7f5a2ece2e7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:20:36.461411Z",
     "start_time": "2025-06-25T20:20:36.449414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(InMemoryDataset):\n",
    "    def __init__(self, root='dataset_path', transform=None, pre_transform=None, df=None, target_type='pretrain', mode='train'):\n",
    "        self.df = df\n",
    "        self.target_type = target_type\n",
    "        super().__init__(root, transform, pre_transform, df)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'raw_{i+1}.pt' for i in range(self.df.shape[0])]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'data_{i+1}.pt' for i in range(self.df.shape[0])]\n",
    "\n",
    "    def len(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        graph = self.graph_list[idx]\n",
    "        mask_graph1 = mask_edges(mask_nodes(copy.deepcopy(graph), 0.3), 0.15)\n",
    "        mask_graph2 = mask_edges(mask_nodes(copy.deepcopy(graph), 0.15), 0.3)\n",
    "\n",
    "        return (graph, mask_graph1, mask_graph2)\n",
    "\n",
    "    def process(self):\n",
    "        smiles_list = self.df['smiles'].values\n",
    "        data_list = []\n",
    "        for i in range(len(smiles_list)):\n",
    "            data = DGDate() # 분자형태의 데이터를 담기위한 빈 공간 느낌\n",
    "            smiles = smiles_list[i]\n",
    "            graph = smiles2graphwithface(smiles)\n",
    "\n",
    "            data.__num_nodes__ = int(graph['num_nodes'])\n",
    "            data.edge_index = torch.from_numpy(graph['edge_index']).to(torch.int64)\n",
    "            data.edge_attr = torch.from_numpy(graph['edge_feat']).to(torch.int64)\n",
    "            data.x = torch.from_numpy(graph['node_feat']).to(torch.int64)\n",
    "\n",
    "            data.ring_mask = torch.from_numpy(graph['ring_mask']).to(torch.bool)\n",
    "            data.ring_index = torch.from_numpy(graph['ring_index']).to(torch.int64)\n",
    "            data.nf_node = torch.from_numpy(graph['nf_node']).to(torch.int64)\n",
    "            data.nf_ring = torch.from_numpy(graph['nf_ring']).to(torch.int64)\n",
    "            data.n_edges = int(graph['n_edges'])\n",
    "            data.n_nodes = int(graph['n_nodes'])\n",
    "            data.n_nfs = int(graph['n_nfs'])\n",
    "\n",
    "            data_list.append(data)\n",
    "        self.smiles_list = smiles_list\n",
    "        self.graph_list = data_list\n"
   ],
   "id": "ab3d2ff820ca23c2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Graph Augmentation\n",
    "\n",
    "- 분자 화합물의 결합을 끊거나, 원자를 drop시킴\n",
    "- 데이터셋에서 데이터를 가져오는 동시에 랜덤으로 원자와 결합을 drop시킴"
   ],
   "id": "b235f293533dfeca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:22:41.944815Z",
     "start_time": "2025-06-25T20:22:41.930815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get(self, idx):\n",
    "    graph = self.graph_list[idx]\n",
    "    mask_graph1 = mask_edges(mask_nodes(copy.deepcopy(graph), 0.3), 0.15)\n",
    "    mask_graph2 = mask_edges(mask_nodes(copy.deepcopy(graph), 0.15), 0.3)\n",
    "\n",
    "    return (graph, mask_graph1, mask_graph2)"
   ],
   "id": "5eb4907e1ff47209",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Graph Contrastive Learning\n",
    "- 모델이 원래 분자 구조를 복원하도록 self-supervised learning하는 학습 기법\n",
    "- Label이 없어도 대량의 분자 구조를 학습하여 모델이 분자의 이해도를 높임\n",
    "- BERT, GPT등이 학습하는 기법을 그래프 구조에 적용하는 방법"
   ],
   "id": "ae564439a5ebf6d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Graph Contrastive Learning에 사용할 Loss\n",
    "- Graph Augmentation을 적용시킨 분자 2개와 원본 분자를 동일하게 예측하도록 학습\n",
    "- TripletMarginLoss : 3개의 벡터간의 거리를 계산하여 Loss값으로 사용함\n",
    "- Contrastive Estimation Loss(loss_cl) : 2개의 변형한 분자 구조도 결국 비슷한 분자이므로 같아지게 학습함\n",
    "- 총 2가지의 Loss를 사용"
   ],
   "id": "a8724be68229df91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:26:46.487836Z",
     "start_time": "2025-06-25T20:26:46.476836Z"
    }
   },
   "cell_type": "code",
   "source": "triplet_loss = nn.TripletMarginLoss(margin=0.1, p=2)",
   "id": "51c70ef9ee31c7f2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:28:21.197329Z",
     "start_time": "2025-06-25T20:28:21.184330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_cl(x1, x2):\n",
    "    T = 0.1\n",
    "    batch_size, _ = x1.size()\n",
    "    x1_abs = x1.norm(dim=1)\n",
    "    x2_abs = x2.norm(dim=1)\n",
    "\n",
    "    sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n",
    "    sim_matrix = torch.exp(sim_matrix / T)\n",
    "    pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "    loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "    loss = - torch.log(loss).mean()\n",
    "    return loss"
   ],
   "id": "2d3fc522832689af",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "- GNN : Graph Neural Network\n",
    "- 그래프 구조 데이터를 처리하기 위한 딥러닝 모델\n",
    "- GNN은 그래프의 노드, 엣지 사이의 관계를 학습하여 노드의 특징과 그래프 구조를 반영한 feature vector를 생성함"
   ],
   "id": "8f50e848f324a15f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T20:34:46.434165Z",
     "start_time": "2025-06-25T20:34:46.421155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MedModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MedModel, self).__init__()\n",
    "        self.ddi = True\n",
    "\n",
    "        ### GNN을 통해 분자의 원자와 결합 정보를 활용하여 Feature Vector를 얻을 수 있음 ###\n",
    "        self.gnn = GNN2(\n",
    "            mlp_hidden_size = 512,\n",
    "            mlp_layer = 4,\n",
    "            latent_size = 128,\n",
    "            use_layer_norm = False,\n",
    "            use_face = True,\n",
    "            # residual = True,\n",
    "            ddi = self.ddi,\n",
    "            dropedge_rate = 0.1,\n",
    "            dropnode_rate = 0.1,\n",
    "            dropout = 0.1,\n",
    "            dropnet = 0.1,\n",
    "            global_reducer = 'sum',\n",
    "            node_reducer = 'sum',\n",
    "            face_reducer = 'sum',\n",
    "            global_pooling = 'sum',\n",
    "            # global_attn = True,\n",
    "            node_attn = True,\n",
    "            face_attn = True,\n",
    "            # use_bn = True,\n",
    "        )\n",
    "\n",
    "        ### Feature Vector의 표현력을 얻기위한 projection ###\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        mol = self.gnn(batch).squeeze(1)\n",
    "        return self.proj(mol)\n"
   ],
   "id": "83ef5acd1d1a362e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GNN 함수 뜯어보기",
   "id": "e89813c095b19c6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T21:32:54.472274Z",
     "start_time": "2025-06-25T21:32:54.462274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('./pretrain/esol.csv')\n",
    "data['dataset'] = 'esol'\n",
    "data = data[['Compound ID', 'smiles', 'dataset']]\n",
    "data.columns = ['sid', 'smiles', 'dataset']\n",
    "data.head()"
   ],
   "id": "8600cbe1d907f3c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               sid                smiles dataset\n",
       "0           citral  CC(C)=CCCC(C)=CC(=O)    esol\n",
       "1       1-Pentene                 CCCC=C    esol\n",
       "2      Tetradecane        CCCCCCCCCCCCCC    esol\n",
       "3  2-Chloropropane               CC(C)Cl    esol\n",
       "4  2-Methylbutanol              CCC(C)CO    esol"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>smiles</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>citral</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>esol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-Pentene</td>\n",
       "      <td>CCCC=C</td>\n",
       "      <td>esol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tetradecane</td>\n",
       "      <td>CCCCCCCCCCCCCC</td>\n",
       "      <td>esol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Chloropropane</td>\n",
       "      <td>CC(C)Cl</td>\n",
       "      <td>esol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-Methylbutanol</td>\n",
       "      <td>CCC(C)CO</td>\n",
       "      <td>esol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 데이터셋, 로더, optimizer, 모델 생성",
   "id": "e33cd56a40c9b81b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = CustomDataset(df=data.loc[:30])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model = MedModel().to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=30, verbose=False)"
   ],
   "id": "3049cd4a880c32b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 꿀팁\n",
    "- ExponentialMovingAverage : 모델의 가중치에 대한 지수 이동 평균을 계산하여 모델의 안정성과 일반화 능력을 향상시키는 방법\n",
    "- 특히 데이터에 노이즈가 심하거나, 사전학습, pseudo labeling을 학습 때 ExponentialMovingAverage를 쓰면 학습이 안정적으로 잘됨"
   ],
   "id": "19782cb5093bb005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Torch Geometric의 데이터 형식",
   "id": "77e1cd68a3e78dfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "graph, aug_graph1, aug_graph2 = batch\n",
    "print(graph.keys())"
   ],
   "id": "7f2f3b45231142bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- batch: Graph는 노드, 엣지로 인해 기존 데이터와 달라 각 노드의 순서가 어느 배치 단위인지에 대한 정보가 있음\n",
    "- ring_mask: 각 노드가 고리(ring) 구조에 속해 있는지를 나타내는 마스트\n",
    "- nf_ring: 고리 구조를 표현하는 feature, ring의 특성을 나타냄\n",
    "- n_nodes: 그래프의 총 노드 수\n",
    "- n_nfs: 노드 특징(node feature)의 차원의 크기\n",
    "- ptr: 포인터 정보를 담고 있음. 각 그래프의 시작 노드를 가리키는 포인터 역할\n",
    "- ring_index: ring의 인덱스 정보를 담고 있음\n",
    "- x: 노드 특징 정보를 담고 있음 -> 분자로 치면 원자의 특징을 담고 있음\n",
    "- n_edges: 그래프의 총 엣지숫자\n",
    "- num_rings: 그래프에 존재하는 ring의 숫자\n",
    "- edge_attr: 엣지의 feature\n",
    "- edge_index: 어떤 노드가 연결되어 있는지 엣지의 연결 정보를 담고 있음"
   ],
   "id": "58c02e3273af16a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('batch :', graph['batch'].shape)\n",
    "print('ring_mask :', graph['ring_mask'].shape)\n",
    "print('nf_ring :', graph['nf_ring'].shape)\n",
    "print('n_nodes :', graph['n_nodes'].shape)\n",
    "print('n_nfs :', graph['n_nfs'].shape)\n",
    "print('ptr :', graph['ptr'].shape)\n",
    "print('ring_index :', graph['ring_index'].shape)\n",
    "print('x :', graph['x'].shape)\n",
    "print('n_edges :', graph['n_edges'].shape)\n",
    "print('num_rings :', graph['num_rings'].shape)\n",
    "print('edge_attr :', graph['edge_attr'].shape)\n",
    "print('edge_index :', graph['edge_index'].shape)\n"
   ],
   "id": "4044f1b15d71879d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph Contrastive Learning",
   "id": "34513a3eee779fda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_loss = 1e6\n",
    "start = 2\n",
    "for epoch in range(1, 31):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = [bat.to(device) for bat in batch]\n",
    "        outputs = [model(bat) for bat in batch]\n",
    "        origin_output = outputs[0]\n",
    "\n",
    "        mask_cl_loss = loss_cl(outputs[1], outputs[2])\n",
    "        mask_t_loss = triplet_loss(outputs[0], outputs[1], outputs[2])\n",
    "\n",
    "        loss = mask_cl_loss + mask_t_loss * 0.1\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        ema.update()\n",
    "\n",
    "        train_loss += loss.cpu.item()\n",
    "\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        torch.save(model.gnn.state_dict(), './model_weights/ognn_pretrain_best.pt')\n",
    "\n",
    "    scheduler.step()\n",
    "    torch.save(\n",
    "        {\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'gnn_state_dict': model.gnn.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'ema_state_dict': ema.state_dict(),\n",
    "        }, f'./model_weights/ognn_pretrain_{epoch}.pt'\n",
    "    )\n",
    "\n",
    "    print(f'EPOCH : {epoch} | trian_loss : {train_loss/len(train_loader):.4f}')\n"
   ],
   "id": "6181ee4aa50034a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine Tuning\n",
    "- 사전학습된 모델에서 FC layer가 추가된 모델\n",
    "- 앞서 저장된 사전학습 모델을 GNN에만 불러서 사용함"
   ],
   "id": "74517c1410fe580"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Smile을 인코딩하는 과정",
   "id": "75a43e132380eaf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chem 모듈 활용\n",
    "- chem모듈을 활용하면 smile 데이터를 python에서 사용할 수 있는 데이터로 변경할 수 있음"
   ],
   "id": "f87b203d5772382e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T21:56:25.903009Z",
     "start_time": "2025-06-25T21:56:25.889010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_atom_feature_dims():\n",
    "    return list(map(len, [\n",
    "        allowable_features['possible_atomic_num_list'],\n",
    "        allowable_features['possible_chirality_list'],\n",
    "        allowable_features['possible_degree_list'],\n",
    "        allowable_features['possible_formal_charge_list'],\n",
    "        allowable_features['possible_numH_list'],\n",
    "        allowable_features['possible_number_radical_e_list'],\n",
    "        allowable_features['possible_hybridization_list'],\n",
    "        allowable_features['possible_is_aromatic_list'],\n",
    "        allowable_features['possible_is_in_ring_list'],\n",
    "    ]))\n",
    "\n",
    "def bond_to_feature_vector(bond):\n",
    "    \"\"\"\n",
    "    Converts rdkit bond object to feature list of indices\n",
    "    : param mol: rdkit mol object\n",
    "    : return: list\n",
    "    \"\"\"\n",
    "    bond_feature = [\n",
    "        safe_index(allowable_features['possible_bond_type_list'], str(bond.GetBondType())),\n",
    "        allowable_features['possible_bond_stereo_list'].index(str(bond.GetStereo())),\n",
    "        allowable_features['possible_is_conjugated_list'].index(str(bond.GetIsConjugated())),\n",
    "    ]\n",
    "    return bond_feature"
   ],
   "id": "d5e5f33d336643c7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Chem을 통해 Atom, Bond의 chirality, degree, formal charge등 다양한 정보를 추출함\n",
    "- 추출한 정보는 추후 모델에서 one-hot인코딩 되고 Projection되어 모델에서 feature로 사용됨"
   ],
   "id": "9288d3a0e2ae04ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T22:21:42.833766Z",
     "start_time": "2025-06-25T22:21:42.821770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def smiles2graphwithface(smiles_string):\n",
    "    if not isinstance(smiles_string, Chem.Mol):\n",
    "        mol = Chem.MolFromSmiles(smiles_string)\n",
    "    else:\n",
    "        mol = smiles_string\n",
    "\n",
    "    # atoms\n",
    "    atom_features_list = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_to_feature_vector(atom))\n",
    "    x = np.array(atom_features_list, dtype=np.int64)\n",
    "\n",
    "    # bonds\n",
    "    num_bond_feature = 3 # bond type, bond stereo, is conjugated\n",
    "    if len(mol.GetBonds()) > 0:\n",
    "        edges_list = []\n",
    "        edge_features_list = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "\n",
    "            edge_feature = bond_to_feature_vector(bond)\n",
    "\n",
    "            # add edges in both directions\n",
    "            edges_list.append((i, j))\n",
    "            edge_features_list.append(edge_feature)\n",
    "            edges_list.append((j, i))\n",
    "            edge_features_list.append(edge_feature)\n",
    "\n",
    "        edge_index = np.array(edges_list, dtype=np.int64).T\n",
    "        edge_attr = np.array(edge_features_list, dtype=np.int64)\n",
    "\n",
    "        faces, left, _ = getface(mol)\n",
    "        num_faces = len(faces)\n",
    "        face_mask = [False] * num_faces\n",
    "        face_index = [[-1, -1]] * len(edges_list)\n",
    "        face_mask[0] = True\n",
    "        for i in range(len(edges_list)):\n",
    "            inface = left[i^1]\n",
    "            outface = left[i]\n",
    "            face_index[i] = [inface, outface]\n",
    "\n",
    "        nf_node = []\n",
    "        nf_ring = []\n",
    "        for i, face in enumerate(faces):\n",
    "            face = list(set(face))\n",
    "            nf_node.extend(face)\n",
    "            nf_ring.extend([i] * len(face))\n",
    "\n",
    "        face_mask = np.array(face_mask, dtype=bool)\n",
    "        face_index = np.array(face_index, dtype=np.int64).T\n",
    "        n_nfs = len(nf_node)\n",
    "        nf_node = np.array(nf_node, dtype=np.int64).reshape(1, -1)\n",
    "        nf_ring = np.array(nf_ring, dtype=np.int64).reshape(1, -1)\n",
    "\n",
    "    else:\n",
    "        edge_index = np.zeros((2, 0), dtype=np.int64)\n",
    "        edge_attr = np.zeros((0, num_bond_feature), dtype=np.int64)\n",
    "        face_mask = np.zeros(0, dtype=bool)\n",
    "        face_index = np.zeros((2, 0), dtype=np.int64)\n",
    "        num_faces = 0\n",
    "        n_nfs = 0\n",
    "        nf_nodes = np.empty((1, 0), dtype=np.int64)\n",
    "        nf_ring = np.empty((1, 0), dtype=np.int64)\n",
    "\n",
    "    graph = dict()\n",
    "    graph[\"edge_index\"] = edge_index\n",
    "    graph[\"edge_feat\"] = edge_attr\n",
    "    graph[\"node_feat\"] = x\n",
    "    graph[\"num_nodes\"] = len(x)\n",
    "\n",
    "    # we do not use the keyword \"face\", since \"face\" is aleady used by torch_geometric\n",
    "    graph[\"ring_mask\"] = face_mask\n",
    "    graph[\"ring_index\"] = face_index\n",
    "    graph[\"num_rings\"] = num_faces\n",
    "    graph[\"n_edges\"] = len(edge_attr)\n",
    "    graph[\"n_nodes\"] = len(x)\n",
    "\n",
    "    graph[\"n_nfs\"] = n_nfs\n",
    "    graph[\"nf_node\"] = nf_node\n",
    "    graph[\"nf_ring\"] = nf_ring\n",
    "\n",
    "    return graph"
   ],
   "id": "e6157c07314f1e42",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- smile을 입력하면 분자의 atom, bond, ring등의 정보를 인코딩하여 graph형태의 dictionary를 반환하여준다.",
   "id": "2c142f92be863444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MedModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MedModel, self).__init__()\n",
    "        self.ddi = True\n",
    "        self.gnn = GNN2(\n",
    "            mlp_hidden_size = 512, mlp_layers = 2, latent_size = 128, use_layer_norm = False,\n",
    "            use_face = True, ddi = self.ddi, dropedge_rate = 0.1, dropnode_rate = 0.1, dropout = 0.1,\n",
    "            dropnet = 0.1, global_reducer = 'sum', node_reducer = 'sum', face_reducer = 'sum', graph_pooling= 'sum',\n",
    "            node_attn = True, face_attn = True\n",
    "        )\n",
    "\n",
    "        state_dict = torch.load('./model_weights/ognn_pretrain_best.pt', map_location='cpu')\n",
    "        self.gnn.load_state_dict(state_dict)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.fc[-1].weight.data.normal_(mean=0.0, std=0.01)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        mol = self.gnn(batch)\n",
    "        out = torch.sigmoid(self.fc(mol).squeeze(1)) * 100 # target이 0~100이어서 sigmoid 후에 100을 곱해주는 형식으로 학습\n",
    "        return out"
   ],
   "id": "18a15447aaf30c43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 데이터셋에서 아래 부분에 해당함",
   "id": "c0b03c57edee7aa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T22:30:08.710493Z",
     "start_time": "2025-06-25T22:30:08.697495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process(self):\n",
    "    smiles_list = self.data['smiles'].values\n",
    "    for i in range(len(smiles_list)):\n",
    "        data = DGData()\n",
    "        smiles = smiles_list[i]\n",
    "        graph = smiles2graphwithface(smiles)"
   ],
   "id": "e1bf23a540a47ad7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T22:32:57.275159Z",
     "start_time": "2025-06-25T22:32:57.263159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ],
   "id": "941ef8eb1a21756a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T22:32:59.276521Z",
     "start_time": "2025-06-25T22:32:59.202520Z"
    }
   },
   "cell_type": "code",
   "source": "plt.hist(data['Inhibition'])",
   "id": "ba910ad3f86652ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([397., 258., 206., 203., 184., 116., 106.,  98.,  62.,  51.]),\n",
       " array([ 0.        ,  9.93815472, 19.87630943, 29.81446415, 39.75261887,\n",
       "        49.69077359, 59.6289283 , 69.56708302, 79.50523774, 89.44339246,\n",
       "        99.38154717]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "args = ...\n",
    "seed_everything(args.seed)\n",
    "\n",
    "test['inhibition'] = 0.0\n",
    "train, valid = train_test_split(data, test_size=0.2, random_state=args.seed)\n",
    "train, valid = train.reset_index(drop=True), valid.reset_index(drop=True)\n",
    "\n",
    "train_dataset = CustomDataset(df=train, mode='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = CustomDataset(df=valid, mode='test')\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "model = MedModel().to(device)\n",
    "mse_loss = nn.MSELoss()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=10, T_mult=1, verbose=False)\n",
    "best_val_loss = 1e6\n",
    "\n",
    "if not os.path.exists('./model_weights'):\n",
    "    os.makedirs('./model_weights')\n",
    "\n",
    "for epoch in range(45):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(args.device)\n",
    "\n",
    "        pred_inhibition = model(batch)\n",
    "        targets = batch.y.to(args.device)\n",
    "\n",
    "        loss = mse_loss(pred_inhibition, targets)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = clip_grad_norm_(model.parameters(), 1000)\n",
    "        optim.step()\n",
    "        ema.update()\n",
    "\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "    model.eval()\n",
    "    valid_preds_inhibition, valid_label_inhibition = [], []\n",
    "\n",
    "    for batch in valid_loader:\n",
    "        batch = batch.to(args.device)\n",
    "        with torch.no.grad():\n",
    "            pred_inhibition = model(batch)\n",
    "            targets = batch.y.to(args.device)\n",
    "\n",
    "            valid_label_inhibition += targets.cpu.to_list()\n",
    "            valid_preds_inhibition += pred_inhibition.cpu.to_list()\n",
    "\n",
    "    inhibition_mse = mean_squared_error(valid_label_inhibition, valid_preds_inhibition)\n",
    "\n",
    "    val_loss = inhibition_mse\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'./model_weights/model_{args.seed}_{args.fold}.pt')\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'EPOCH : {epoch} | train_loss : {train_loss/len(train_loader):.4f} | val_loss : {val_loss:.4f}')"
   ],
   "id": "2fcd8b22f8b6d4fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 학습 코드 뜯어보기",
   "id": "63a8bab25f725a31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 기본 학습 모듈",
   "id": "5041bb30f3cbdad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = MedModel().to(args.device)\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=10, T_mult=1, verbose=False)"
   ],
   "id": "7ac37afe7d6d8e2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 모델: 사전학습에도 사용한 GNN에 fc layer를 추가\n",
    "- 회귀이므로 mse loss 사용\n",
    "- ema: 사전학습이 아니어도 ema는 사용하면 좋다 (decay가 0.995라는 것은 지수이동에서 parameter의 변화율을 0.995만큼 반영한다는 것)\n",
    "- scheduler\n",
    "- WarmUp scheduler: 학습률을 줄였다가 늘리기를 반복하면서 모델을 warm up하는 방법\n",
    "- CosineAnnealingWarmRestarts가 웬만한 task에서는 가장 잘 되지만 데이터가 노이즈가 심하거나 학습이 잘 안되는 경우는 WarmUp사용은 비추천"
   ],
   "id": "b648b94558f5ff4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss = mse_loss(pred_inhibition, targets)\n",
    "\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "grad = clip_grad_norm_(model.parameters(), 1000)\n",
    "optim.step()\n",
    "ema.update()"
   ],
   "id": "bd93214f3134bbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- ema는 optimizer뒤에 위치시킴\n",
   "id": "fccea9b2d59195a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 오버피팅 방지",
   "id": "51d0754a49217310"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### nn.Linear weight값을 정규화\n",
    "- 예측값이 회귀처럼 정교해야하는 경우에는 도움이 될 때가 가끔 있음"
   ],
   "id": "320563f27841f53e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "self.fc[-1].weight.data.normal_(mean=0.0, std=0.01)",
   "id": "7fdbd78f0025506d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Gradient Norm\n",
    "- 계산한 Gradient를 clipping해주어서 일정 숫자가 넘지 않게 -> gradient exploding을 방지하여줌"
   ],
   "id": "271bb30c4cffd353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "grad = clip_grad_norm_(model.parameters(), 1000)",
   "id": "32d96de0fe4fd274"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 예측값 정규화\n",
    "- 저해율 값은 0~100 사이 이므로 sigmoid함수로 정규화 시켜서 학습을 더 안정적으로 하여줌"
   ],
   "id": "822e33cb7fb6894a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "out = torch.sigmoid(self.fc(mol).squeeze(1)) * 100",
   "id": "eb0f1e70b468ccfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CrossValidation과 Seed앙상블",
   "id": "138c87dff99e7b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for seed in [0, 1000, 2000, 1113, 2023]:\n",
    "    ksplit = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    for k, (train_idx, valid_idx) in enumerate(ksplit.split(data)):\n",
    "        run()\n",
    "\n",
    "        ..."
   ],
   "id": "7f746d3a1257da19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 대회에서는 다양한 모델의 앙상블 + 시드, Cross Validation앙상블이 필수\n",
    "- 인공지능은 어떤 데이터를 학습하는지 그리고 random으로 정해지는 모델의 시작 weight값이 어떻게 되는지 등 사소한 영향을 많이 받음\n",
    "- 따라서 여러 seed, 그리고 학습 데이터도 여러번 분할하여 모델을 여러개 생성하여 앙상블하는 것을 추천\n",
    "- 대회가 아닌 연구라면 여러번 반복해서 구한 성능의 신뢰구간을 제시해야하기도 함"
   ],
   "id": "d9bc79882897a04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c5b056a4bc1a5bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
